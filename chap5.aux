\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{PyTorch_2019}
\citation{Jalas_2021_PRL}
\citation{Dolier_2022_NJoP}
\citation{Loughran_2023_HPLSE}
\citation{Djordjevic_2021_PPCF}
\citation{Schmitz_2023_LaPB}
\citation{George_2019_HPLSE}
\citation{Fuchs_2005_Nat}
\citation{Desai_2024_Zenodo,Desai_2025_Zenodo}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Machine Learning Methods Applied to Synthetic Ion Acceleration Data}{55}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:5}{{5}{55}{Machine Learning Methods Applied to Synthetic Ion Acceleration Data}{chapter.5}{}}
\newlabel{ch:5@cref}{{[chapter][5][]5}{[1][55][]55}}
\citation{Desai_2024_CPP,Desai_2025_APL}
\citation{Mora_2003_PRL}
\citation{Fuchs_2005_Nat}
\citation{Mora_2003_PRL}
\citation{Crow_1975_JPP,Kishimoto_1983_PoF}
\citation{Crow_1975_JPP}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Modified Fuchs et. al. Model}{56}{section.5.1}\protected@file@percent }
\newlabel{sec:fuchs_model}{{5.1}{56}{Modified Fuchs et. al. Model}{section.5.1}{}}
\newlabel{sec:fuchs_model@cref}{{[section][1][5]5.1}{[1][56][]56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Plasma Expansion into a Vacuum}{56}{subsection.5.1.1}\protected@file@percent }
\newlabel{eq:crow_field}{{5.1}{57}{Plasma Expansion into a Vacuum}{equation.5.1.1}{}}
\newlabel{eq:crow_field@cref}{{[equation][1][5]5.1}{[1][56][]57}}
\newlabel{eq:omegapi}{{5.3}{57}{Plasma Expansion into a Vacuum}{equation.5.1.3}{}}
\newlabel{eq:omegapi@cref}{{[equation][3][5]5.3}{[1][57][]57}}
\newlabel{eq:soundspeed}{{5.4}{57}{Plasma Expansion into a Vacuum}{equation.5.1.4}{}}
\newlabel{eq:soundspeed@cref}{{[equation][4][5]5.4}{[1][57][]57}}
\newlabel{eq:continuity}{{5.6a}{57}{Plasma Expansion into a Vacuum}{equation.5.1.6a}{}}
\newlabel{eq:continuity@cref}{{[subequation][1][5,6]5.6a}{[1][57][]57}}
\newlabel{eq:lorentz_mora}{{5.6b}{57}{Plasma Expansion into a Vacuum}{equation.5.1.6b}{}}
\newlabel{eq:lorentz_mora@cref}{{[subequation][2][5,6]5.6b}{[1][57][]57}}
\citation{Mora_2003_PRL}
\citation{Mora_2003_PRL}
\newlabel{eq:selfsimilarvelocity}{{5.7}{58}{Plasma Expansion into a Vacuum}{equation.5.1.7}{}}
\newlabel{eq:selfsimilarvelocity@cref}{{[equation][7][5]5.7}{[1][57][]58}}
\newlabel{eq:selfsimilardensity}{{5.8}{58}{Plasma Expansion into a Vacuum}{equation.5.1.8}{}}
\newlabel{eq:selfsimilardensity@cref}{{[equation][8][5]5.8}{[1][58][]58}}
\newlabel{eq:selfsimilarefield}{{5.9}{58}{Plasma Expansion into a Vacuum}{equation.5.1.9}{}}
\newlabel{eq:selfsimilarefield@cref}{{[equation][9][5]5.9}{[1][58][]58}}
\newlabel{eq:mora_xfront}{{5.10}{58}{Plasma Expansion into a Vacuum}{equation.5.1.10}{}}
\newlabel{eq:mora_xfront@cref}{{[equation][10][5]5.10}{[1][58][]58}}
\citation{Mora_2005_PRE,Passoni_2010_NJoP,Schreiber_2006_PRL}
\citation{Fuchs_2005_Nat}
\newlabel{fig:fig1_mora}{{5.1a}{59}{Subfigure 5 5.1a}{subfigure.5.1.1}{}}
\newlabel{sub@fig:fig1_mora}{{(a)}{a}{Subfigure 5 5.1a\relax }{subfigure.5.1.1}{}}
\newlabel{fig:fig1_mora@cref}{{[subfigure][1][5,1]5.1a}{[1][58][]59}}
\newlabel{fig:fig2_mora}{{5.1b}{59}{Subfigure 5 5.1b}{subfigure.5.1.2}{}}
\newlabel{sub@fig:fig2_mora}{{(b)}{b}{Subfigure 5 5.1b\relax }{subfigure.5.1.2}{}}
\newlabel{fig:fig2_mora@cref}{{[subfigure][2][5,1]5.1b}{[1][58][]59}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces The net charge density (left) as a function of position $x / c_s t$ and normalized electric field $E/E_0$ (right) for $\omega _{pi} t = 50$ taken from Fig 1 and 2 in Mora's Paper \cite  {Mora_2003_PRL}. On the right, the self-similar electric field from \autoref {eq:selfsimilarefield} is plotted with a dashed line.}}{59}{figure.caption.47}\protected@file@percent }
\newlabel{eq:mora_xfront_simple}{{5.14}{59}{Plasma Expansion into a Vacuum}{equation.5.1.14}{}}
\newlabel{eq:mora_xfront_simple@cref}{{[equation][14][5]5.14}{[1][59][]59}}
\newlabel{eq:mora_maxE}{{5.15}{59}{Plasma Expansion into a Vacuum}{equation.5.1.15}{}}
\newlabel{eq:mora_maxE@cref}{{[equation][15][5]5.15}{[1][59][]59}}
\newlabel{eq:numprotons}{{5.17}{59}{Plasma Expansion into a Vacuum}{equation.5.1.17}{}}
\newlabel{eq:numprotons@cref}{{[equation][17][5]5.17}{[1][59][]59}}
\newlabel{eq:dNdE}{{5.18}{59}{Plasma Expansion into a Vacuum}{equation.5.1.18}{}}
\newlabel{eq:dNdE@cref}{{[equation][18][5]5.18}{[1][59][]59}}
\citation{Key_1998_PoP}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Modified Fuchs Model}{60}{subsection.5.1.2}\protected@file@percent }
\newlabel{sec:fuchsv1}{{5.1.2}{60}{Modified Fuchs Model}{subsection.5.1.2}{}}
\newlabel{sec:fuchsv1@cref}{{[subsection][2][5,1]5.1.2}{[1][59][]60}}
\newlabel{eq:fuchs_maxE}{{5.19}{60}{Modified Fuchs Model}{equation.5.1.19}{}}
\newlabel{eq:fuchs_maxE@cref}{{[equation][19][5]5.19}{[1][60][]60}}
\newlabel{eq:fuchs_multiplier}{{5.20}{60}{Modified Fuchs Model}{equation.5.1.20}{}}
\newlabel{eq:fuchs_multiplier@cref}{{[equation][20][5]5.20}{[1][60][]60}}
\newlabel{eq:dNdE_Fuchs}{{5.23}{60}{Modified Fuchs Model}{equation.5.1.23}{}}
\newlabel{eq:dNdE_Fuchs@cref}{{[equation][23][5]5.23}{[1][60][]60}}
\citation{Fuchs_2005_Nat}
\citation{Decker_1996_PoP}
\newlabel{eq:fuchs_N}{{5.24}{61}{Modified Fuchs Model}{equation.5.1.24}{}}
\newlabel{eq:fuchs_N@cref}{{[equation][24][5]5.24}{[1][61][]61}}
\newlabel{eq:fuchs_totE}{{5.25}{61}{Modified Fuchs Model}{equation.5.1.25}{}}
\newlabel{eq:fuchs_totE@cref}{{[equation][25][5]5.25}{[1][61][]61}}
\newlabel{eq:fuchs_avgE}{{5.26}{61}{Modified Fuchs Model}{equation.5.1.26}{}}
\newlabel{eq:fuchs_avgE@cref}{{[equation][26][5]5.26}{[1][61][]61}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Further Model Modifications}{61}{subsection.5.1.3}\protected@file@percent }
\newlabel{sec:fuchsv2}{{5.1.3}{61}{Further Model Modifications}{subsection.5.1.3}{}}
\newlabel{sec:fuchsv2@cref}{{[subsection][3][5,1]5.1.3}{[1][61][]61}}
\newlabel{eq:d_eff}{{5.27}{61}{Further Model Modifications}{equation.5.1.27}{}}
\newlabel{eq:d_eff@cref}{{[equation][27][5]5.27}{[1][61][]61}}
\citation{Desai_2025_APL}
\citation{Desai_2025_APL}
\citation{Desai_2025_APL}
\citation{Morrison_2018_NJoP}
\citation{Desai_2025_APL}
\citation{Morrison_2018_NJoP}
\citation{Desai_2025_APL}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces The electron density profile of the pre-expanded target is depicted for various times $t_0$. In this figure, $n(0) \equiv n_\text  {max}$. Taken from Desai et al. \cite  {Desai_2025_APL} where $z$ was used as the distance along the laser axis instead of $x$ as done in this work. }}{62}{figure.caption.48}\protected@file@percent }
\newlabel{fig:density_profile}{{5.2}{62}{The electron density profile of the pre-expanded target is depicted for various times $t_0$. In this figure, $n(0) \equiv n_\text {max}$. Taken from Desai et al. \cite {Desai_2025_APL} where $z$ was used as the distance along the laser axis instead of $x$ as done in this work}{figure.caption.48}{}}
\newlabel{fig:density_profile@cref}{{[figure][2][5]5.2}{[1][62][]62}}
\newlabel{eq:vetch}{{5.28}{62}{Further Model Modifications}{equation.5.1.28}{}}
\newlabel{eq:vetch@cref}{{[equation][28][5]5.28}{[1][62][]62}}
\citation{Desai_2024_CPP}
\citation{George_2019_HPLSE}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces The dotted black line shows the maximum proton energy predicted by \autoref {eq:fuchs_maxE} with the pump depletion considerations in \autoref {sec:fuchsv2} assuming $t_0 = \SI {60}{\pico \second }$, $I_0 = 10^{19} \text  {W cm}^{-2}$, $\kappa =10^{-7}$, $d=\SI {0.5}{\micro \meter }$. The red stars indicate the predicted positions of maximum proton energy $\sim \SI {12}{\micro \meter }$. This plot is overlayed on top of an experimental maximum proton energy distribution from Morrison et. al. \cite  {Morrison_2018_NJoP}. This figure is taken from Desai et. al. \cite  {Desai_2025_APL}.}}{63}{figure.caption.49}\protected@file@percent }
\newlabel{fig:energy_dip_morrison}{{5.3}{63}{The dotted black line shows the maximum proton energy predicted by \autoref {eq:fuchs_maxE} with the pump depletion considerations in \autoref {sec:fuchsv2} assuming $t_0 = \SI {60}{\pico \second }$, $I_0 = 10^{19} \text {W cm}^{-2}$, $\kappa =10^{-7}$, $d=\SI {0.5}{\micro \meter }$. The red stars indicate the predicted positions of maximum proton energy $\sim \SI {12}{\micro \meter }$. This plot is overlayed on top of an experimental maximum proton energy distribution from Morrison et. al. \cite {Morrison_2018_NJoP}. This figure is taken from Desai et. al. \cite {Desai_2025_APL}}{figure.caption.49}{}}
\newlabel{fig:energy_dip_morrison@cref}{{[figure][3][5]5.3}{[1][62][]63}}
\newlabel{eq:tau_etch}{{5.30}{63}{Further Model Modifications}{equation.5.1.30}{}}
\newlabel{eq:tau_etch@cref}{{[equation][30][5]5.30}{[1][62][]63}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}First Analysis}{63}{section.5.2}\protected@file@percent }
\newlabel{sec:first_analysis}{{5.2}{63}{First Analysis}{section.5.2}{}}
\newlabel{sec:first_analysis@cref}{{[section][2][5]5.2}{[1][63][]63}}
\citation{Djordjevic_2021_PPCF}
\citation{Miller_1984_AmStat}
\citation{2023_RAPIDS}
\citation{Gardner_2018_GPytorch}
\citation{Tietz_2017_Skorch}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Methods}{64}{subsection.5.2.1}\protected@file@percent }
\citation{Desai_2024_CPP}
\citation{Desai_2024_CPP}
\citation{Desai_2024_CPP}
\citation{Desai_2024_CPP}
\citation{Wang_2019_GPytorch}
\citation{Wang_2019_GPytorch}
\citation{Desai_2024_CPP}
\citation{Desai_2024_CPP}
\citation{Desai_2024_CPP}
\citation{Desai_2024_CPP}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Optimal hyperparameters found through grid searches and cross-validation using only the training set for the results in \autoref {sec:first_analysis}.}}{65}{table.caption.50}\protected@file@percent }
\newlabel{tab:hps1}{{5.1}{65}{Optimal hyperparameters found through grid searches and cross-validation using only the training set for the results in \autoref {sec:first_analysis}}{table.caption.50}{}}
\newlabel{tab:hps1@cref}{{[table][1][5]5.1}{[1][65][]65}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Results}{65}{subsection.5.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces MAPE versus number of training points from ML model predictions for (a) max proton energy, (b) total proton energy, (c) average proton energy and noisy testing data. Each panel shows results from (solid) 0\%, (dashed) 15\% and (dotted) 30\% added noise in the data. Black lines with different line types indicate the MAPE between the noisy and noiseless data. Because we only compare ML models to noisy data in this figure, these black lines indicate the best that any ML model could conceivably do. Figure and caption taken from Figure 3 of Desai et al. \cite  {Desai_2024_CPP}.}}{66}{figure.caption.51}\protected@file@percent }
\newlabel{fig:mape_3levels}{{5.4}{66}{MAPE versus number of training points from ML model predictions for (a) max proton energy, (b) total proton energy, (c) average proton energy and noisy testing data. Each panel shows results from (solid) 0\%, (dashed) 15\% and (dotted) 30\% added noise in the data. Black lines with different line types indicate the MAPE between the noisy and noiseless data. Because we only compare ML models to noisy data in this figure, these black lines indicate the best that any ML model could conceivably do. Figure and caption taken from Figure 3 of Desai et al. \cite {Desai_2024_CPP}}{figure.caption.51}{}}
\newlabel{fig:mape_3levels@cref}{{[figure][4][5]5.4}{[1][65][]66}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Solid lines show the typical MAPE in (a) maximum proton energy, (b) total proton energy, and (c) average proton energy when the models (which were trained on 2000 synthetic data points with noise) are evaluated on data with different levels of noise. Dashed lines show the typical error when those same ML models are evaluated on noiseless test data. Black solid lines indicate the MAPE between the noisy and noiseless data. Figure and caption taken from Figure 4 of Desai et al. \cite  {Desai_2024_CPP}.}}{67}{figure.caption.52}\protected@file@percent }
\newlabel{fig:mape_noise}{{5.5}{67}{Solid lines show the typical MAPE in (a) maximum proton energy, (b) total proton energy, and (c) average proton energy when the models (which were trained on 2000 synthetic data points with noise) are evaluated on data with different levels of noise. Dashed lines show the typical error when those same ML models are evaluated on noiseless test data. Black solid lines indicate the MAPE between the noisy and noiseless data. Figure and caption taken from Figure 4 of Desai et al. \cite {Desai_2024_CPP}}{figure.caption.52}{}}
\newlabel{fig:mape_noise@cref}{{[figure][5][5]5.5}{[1][65][]67}}
\citation{Desai_2024_CPP}
\citation{Desai_2024_CPP}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces The execution time of the different ML models averaged across noise levels in computing the maximum, total, and average proton energies. Figure and caption taken from Figure 5 of Desai et al. \cite  {Desai_2024_CPP}.}}{68}{figure.caption.53}\protected@file@percent }
\newlabel{fig:execution_time}{{5.6}{68}{The execution time of the different ML models averaged across noise levels in computing the maximum, total, and average proton energies. Figure and caption taken from Figure 5 of Desai et al. \cite {Desai_2024_CPP}}{figure.caption.53}{}}
\newlabel{fig:execution_time@cref}{{[figure][6][5]5.6}{[1][65][]68}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Optimization Task}{68}{subsection.5.2.3}\protected@file@percent }
\newlabel{eq:fuchsv1_function}{{5.31}{68}{Optimization Task}{equation.5.2.31}{}}
\newlabel{eq:fuchsv1_function@cref}{{[equation][31][5]5.31}{[1][68][]68}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Parameters that produce maximum proton energy cutoffs in three different desired ranges: 1.0~MeV, 0.5~MeV and 0.25~MeV. Combinations of thickness and focal distance that produce these energy cutoffs (irrespective of the laser to proton conversion efficiency) are shown with dotted red lines. With each red line we also show with dotted gray lines the thicknesses and focal distances that produce proton energy cutoffs that are +15\% or -15\% of the cutoff goal. Green shaded areas show regions where the laser to proton conversion efficiency is high (i.e. within 5\% of the optimal value). A green star shows the ideal conditions for maximizing the proton conversion efficiency. The blue region corresponds to using all the terms in \autoref {eq:fuchsv1_function} and the blue star indicates the ideal conditions according to that minimization scheme. Figure and caption taken from Figure 6 of Desai et al. \cite  {Desai_2024_CPP}.}}{69}{figure.caption.54}\protected@file@percent }
\newlabel{fig:banana}{{5.7}{69}{Parameters that produce maximum proton energy cutoffs in three different desired ranges: 1.0~MeV, 0.5~MeV and 0.25~MeV. Combinations of thickness and focal distance that produce these energy cutoffs (irrespective of the laser to proton conversion efficiency) are shown with dotted red lines. With each red line we also show with dotted gray lines the thicknesses and focal distances that produce proton energy cutoffs that are +15\% or -15\% of the cutoff goal. Green shaded areas show regions where the laser to proton conversion efficiency is high (i.e. within 5\% of the optimal value). A green star shows the ideal conditions for maximizing the proton conversion efficiency. The blue region corresponds to using all the terms in \autoref {eq:fuchsv1_function} and the blue star indicates the ideal conditions according to that minimization scheme. Figure and caption taken from Figure 6 of Desai et al. \cite {Desai_2024_CPP}}{figure.caption.54}{}}
\newlabel{fig:banana@cref}{{[figure][7][5]5.7}{[1][65][]69}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Parameters that produce maximum proton energy cutoffs according to three trained ML Models on 2,000 data points with 30\% added noise: (a) GPR, (b) SVR, (c) NN compared against the red and gray lines plotted in \autoref {fig:banana}. The green and blue shaded regions are scatter plots of a subset of evaluated points that fall within 5\% of the model's predicted optimum according to the same criteria in \autoref {fig:banana}. Figure and caption taken from Figure 7 of Desai et al. \cite  {Desai_2024_CPP}.}}{70}{figure.caption.55}\protected@file@percent }
\newlabel{fig:banana3}{{5.8}{70}{Parameters that produce maximum proton energy cutoffs according to three trained ML Models on 2,000 data points with 30\% added noise: (a) GPR, (b) SVR, (c) NN compared against the red and gray lines plotted in \autoref {fig:banana}. The green and blue shaded regions are scatter plots of a subset of evaluated points that fall within 5\% of the model's predicted optimum according to the same criteria in \autoref {fig:banana}. Figure and caption taken from Figure 7 of Desai et al. \cite {Desai_2024_CPP}}{figure.caption.55}{}}
\newlabel{fig:banana3@cref}{{[figure][8][5]5.8}{[1][68][]70}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Second Analysis}{70}{section.5.3}\protected@file@percent }
\newlabel{sec:second_analysis}{{5.3}{70}{Second Analysis}{section.5.3}{}}
\newlabel{sec:second_analysis@cref}{{[section][3][5]5.3}{[1][70][]70}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Methods}{70}{subsection.5.3.1}\protected@file@percent }
\citation{Morrison_2018_NJoP}
\citation{Hensman_2014_SVGP}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Optimal hyper-parameters including the root mean square error (RMSE) and mean fit time, determined from a grid search of hyperparameters for the NN, POLY, and SVGP. For the NN, the batch size (BS), learning rate decay ($\gamma $), patience (P), learning rate (LR), and architectures (layers x neurons per layer) were changed throughout the scans. For the POLY, the regularization parameter ($\alpha $) and degree (deg) were varied. For the SVGP, the number of inducing points (IP), latent functions (LF), and learning rate (LR) were changed throughout the scans.}}{72}{table.caption.56}\protected@file@percent }
\newlabel{tab:hps2}{{5.2}{72}{Optimal hyper-parameters including the root mean square error (RMSE) and mean fit time, determined from a grid search of hyperparameters for the NN, POLY, and SVGP. For the NN, the batch size (BS), learning rate decay ($\gamma $), patience (P), learning rate (LR), and architectures (layers x neurons per layer) were changed throughout the scans. For the POLY, the regularization parameter ($\alpha $) and degree (deg) were varied. For the SVGP, the number of inducing points (IP), latent functions (LF), and learning rate (LR) were changed throughout the scans}{table.caption.56}{}}
\newlabel{tab:hps2@cref}{{[table][2][5]5.2}{[1][71][]72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Results}{72}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Optimization Task}{72}{subsection.5.3.3}\protected@file@percent }
\newlabel{eq:obj_function_v2}{{5.32}{72}{Optimization Task}{equation.5.3.32}{}}
\newlabel{eq:obj_function_v2@cref}{{[equation][32][5]5.32}{[1][72][]72}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Model training results using data with 10\% added noise. Testing MAPE (a) is plotted for the three ML models against the number of training points and averaged between results for maximum, average, and total proton energy. The training time (b) of the ML models in minutes is plotted on a logarithmic scale. The vertical bars are standard deviations computed from running the training splits 3 times with different seeds to control the data splitting and random parameter initialization of the NN and SVGP models.}}{73}{figure.caption.57}\protected@file@percent }
\newlabel{fig:train_time_accuracy}{{5.9}{73}{Model training results using data with 10\% added noise. Testing MAPE (a) is plotted for the three ML models against the number of training points and averaged between results for maximum, average, and total proton energy. The training time (b) of the ML models in minutes is plotted on a logarithmic scale. The vertical bars are standard deviations computed from running the training splits 3 times with different seeds to control the data splitting and random parameter initialization of the NN and SVGP models}{figure.caption.57}{}}
\newlabel{fig:train_time_accuracy@cref}{{[figure][9][5]5.9}{[1][72][]73}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Testing MAPE is plotted against different levels of gaussian noise using the full training dataset for the three models with the three output energy results averaged.}}{74}{figure.caption.58}\protected@file@percent }
\newlabel{fig:noise_accuracy}{{5.10}{74}{Testing MAPE is plotted against different levels of gaussian noise using the full training dataset for the three models with the three output energy results averaged}{figure.caption.58}{}}
\newlabel{fig:noise_accuracy@cref}{{[figure][10][5]5.10}{[1][72][]74}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Colormaps in the 2D parameter space of target thickness and target focal position that display (left panel) the maximum proton energy (i.e. energy cutoff $KE_{\rm  c}$) and (right panel) laser to proton energy conversion efficiency $\eta _{p}$ as calculated from the modified Fuchs et al model. These plots were generated assuming 14.14~mJ of laser energy and a pre-pulse contrast of $10^{-7}$.}}{75}{figure.caption.59}\protected@file@percent }
\newlabel{fig:energy_efficiency}{{5.11}{75}{Colormaps in the 2D parameter space of target thickness and target focal position that display (left panel) the maximum proton energy (i.e. energy cutoff $KE_{\rm c}$) and (right panel) laser to proton energy conversion efficiency $\eta _{p}$ as calculated from the modified Fuchs et al model. These plots were generated assuming 14.14~mJ of laser energy and a pre-pulse contrast of $10^{-7}$}{figure.caption.59}{}}
\newlabel{fig:energy_efficiency@cref}{{[figure][11][5]5.11}{[1][72][]75}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Constrained Data Campaign}{75}{subsection.5.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Colormaps that show estimates of \autoref {eq:obj_function_v2} assuming $KE_{\rm  c,goal} = 1$~MeV for the three ML models (NN, POLY and SVGP) and the modified Fuchs et al. model dataset with no added noise (FUCHS). The modified Fuchs et al. model with 30\% added noise was used to produce the training data for the ML models. For each $\beta $ value (i.e. each column), the same color levels are used in order to facilitate comparison between the models. A cyan colored star is placed at the location where each ML model predicts a minimum value for \autoref {eq:obj_function_v2} which can be compared to the analytic model prediction indicated by a white star.}}{76}{figure.caption.60}\protected@file@percent }
\newlabel{fig:obn_fn_model}{{5.12}{76}{Colormaps that show estimates of \autoref {eq:obj_function_v2} assuming $KE_{\rm c,goal} = 1$~MeV for the three ML models (NN, POLY and SVGP) and the modified Fuchs et al. model dataset with no added noise (FUCHS). The modified Fuchs et al. model with 30\% added noise was used to produce the training data for the ML models. For each $\beta $ value (i.e. each column), the same color levels are used in order to facilitate comparison between the models. A cyan colored star is placed at the location where each ML model predicts a minimum value for \autoref {eq:obj_function_v2} which can be compared to the analytic model prediction indicated by a white star}{figure.caption.60}{}}
\newlabel{fig:obn_fn_model@cref}{{[figure][12][5]5.12}{[1][74][]76}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Comparison metrics evaluated from \autoref {fig:obn_fn_model}. The RMSE row shows the root mean squared error between the colormap values of the ML models and the analytic model for each value of $\beta $. The $\Delta _\text  {opt}$ row calculates the Euclidean distance between the predicted optimum and true optimum (i.e. distance in $\mu $m between the cyan and white stars in \autoref {fig:obn_fn_model}).}}{77}{table.caption.61}\protected@file@percent }
\newlabel{tab:opt_results}{{5.3}{77}{Comparison metrics evaluated from \autoref {fig:obn_fn_model}. The RMSE row shows the root mean squared error between the colormap values of the ML models and the analytic model for each value of $\beta $. The $\Delta _\text {opt}$ row calculates the Euclidean distance between the predicted optimum and true optimum (i.e. distance in $\mu $m between the cyan and white stars in \autoref {fig:obn_fn_model})}{table.caption.61}{}}
\newlabel{tab:opt_results@cref}{{[table][3][5]5.3}{[1][75][]77}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Synthetic data was generated in one of two ``campaigns''. In (a) campaign 1, the target focus and thickness is varied in discrete steps and each blue dot varies the laser energy from minimum to maximum. In (b) campaign 2, the depicted intensity and contrast looping is performed for discrete steps in target thickness from $0.5~\mu $m to $5\mu $m}}{78}{figure.caption.62}\protected@file@percent }
\newlabel{fig:zigzag}{{5.13}{78}{Synthetic data was generated in one of two ``campaigns''. In (a) campaign 1, the target focus and thickness is varied in discrete steps and each blue dot varies the laser energy from minimum to maximum. In (b) campaign 2, the depicted intensity and contrast looping is performed for discrete steps in target thickness from $0.5~\mu $m to $5\mu $m}{figure.caption.62}{}}
\newlabel{fig:zigzag@cref}{{[figure][13][5]5.13}{[1][78][]78}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Testing set MAPE evaluated on several ML models trained on data combined from two separate campaigns shown in \autoref {fig:zigzag}. The dashed line differs from the solid blue line in the polynomial degree.}}{79}{figure.caption.63}\protected@file@percent }
\newlabel{fig:split_accuracy}{{5.14}{79}{Testing set MAPE evaluated on several ML models trained on data combined from two separate campaigns shown in \autoref {fig:zigzag}. The dashed line differs from the solid blue line in the polynomial degree}{figure.caption.63}{}}
\newlabel{fig:split_accuracy@cref}{{[figure][14][5]5.14}{[1][79][]79}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Conclusion}{79}{section.5.4}\protected@file@percent }
\citation{Desai_2024_Zenodo,Desai_2025_Zenodo}
\@setckpt{chap5}{
\setcounter{page}{81}
\setcounter{equation}{32}
\setcounter{enumi}{5}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{17}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{14}
\setcounter{table}{3}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{section@level}{0}
\setcounter{Item}{5}
\setcounter{Hfootnote}{17}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{0}
\setcounter{NAT@ctr}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{2}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{parentequation}{0}
\setcounter{su@anzahl}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
}
